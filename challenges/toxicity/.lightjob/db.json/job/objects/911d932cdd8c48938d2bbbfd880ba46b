{"problem": "challenges.toxicity.problem", "start": "2018-02-26 08:43:24.744436", "content": {"problem": "challenges.toxicity.problem", "info": {"batch_size": 64, "nb_units": 100, "lr": 0.001, "epochs": 1}, "codes": {"classifier": "import numpy as np\nimport re\nfrom sklearn.metrics import roc_auc_score\nfrom gensim.models.wrappers import FastText\nfrom keras.layers import *\nfrom keras.optimizers import Adam\nfrom keras.models import Model\n\nft = FastText.load_fasttext_format('wiki.en.bin')\n#ft = None\nmax_length = 100\nnb_outputs = 6\nvec_size = 300\nbatch_size = 64\n\n\ndef normalize(s):\n    \"\"\"\n    Given a text, cleans and normalizes it. Feel free to add your own stuff.\n    \"\"\"\n    s = s.lower()\n    # Replace ips\n    # Isolate punctuation\n    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n    # Remove some special characters\n    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n    # Replace numbers and symbols with language\n    s = s.replace('&', ' and ')\n    s = s.replace('@', ' at ')\n    s = s.replace('0', ' zero ')\n    s = s.replace('1', ' one ')\n    s = s.replace('2', ' two ')\n    s = s.replace('3', ' three ')\n    s = s.replace('4', ' four ')\n    s = s.replace('5', ' five ')\n    s = s.replace('6', ' six ')\n    s = s.replace('7', ' seven ')\n    s = s.replace('8', ' eight ')\n    s = s.replace('9', ' nine ')\n    return s\n\n\ndef fe(doc):\n    s = doc\n    s = normalize(s)\n    s = s.split(' ')\n    s = s[0:max_length]\n    s = [a.strip() for a in s]\n    s = [a for a in s if a in ft]\n    x = np.zeros((max_length, vec_size))\n    x[0:len(s)] = np.array([ft[a] for a in s])\n    return x\n\ndef avg_auc(clf, X, y):\n    aucs = []\n    y_pred = clf.predict_proba(X)\n    for i in range(y.shape[1]):\n        aucs.append(roc_auc_score(y[:, i], y_pred[i][:, 1]))\n    return np.mean(aucs)\n\n\nclass Classifier:\n\n    def __init__(self):\n        pass\n\n    def fit(self, X, y):\n        inp = Input(shape=(max_length, vec_size))\n        x = GRU(100)(inp)\n        out = Dense(nb_outputs, activation='sigmoid')(x)\n        model = Model(inputs=inp, outputs=out)\n        opt = Adam(lr=0.001)\n        model.compile(loss='binary_crossentropy', optimizer=opt)\n        def gen():\n            while True:\n                for i in range(0, len(X), batch_size):\n                    xb = X[i:i+batch_size]\n                    yb = y[i:i+batch_size]\n                    xb = [fe(s) for s in xb]\n                    xb = np.array(xb)\n                    yield xb, yb\n            auc = avg_auc(self.model, X, y)\n            print('Train auc : ' + str(auc))\n\n        steps_per_epoch = len(X) // batch_size\n        model.fit_generator(gen(), steps_per_epoch=steps_per_epoch, epochs=1)\n        self.model = model\n    \n    def predict(self, X):\n        pr = self.predict_proba(X)\n        pr = np.array(pr)#6,ex,2\n        pr = pr.transpose((1, 0, 2))\n        pr = pr[:, :, 1]\n        return (pr > 0.5).astype('float32')\n\n    def predict_proba(self, X):\n        yl = []\n        for i in range(0, len(X), batch_size):\n            xb = X[i:i + batch_size]\n            xb = [fe(x) for x in xb]\n            xb = np.array(xb)\n            y = self.model.predict(xb)\n            yl.append(y)\n        y = np.concatenate(yl, axis=0)\n        out = []\n        for i in range(y.shape[1]):\n            o = np.vstack((1 - y[:, i], y[:, i])).T\n            out.append(o)\n        return out\n"}, "sampler": "challenges.toxicity.samplers.gru"}, "stats": {"train": {"avg_auc": [0.9738247356233695, 0.9745391935677531, 0.9745498468483832, 0.9759185556119462, 0.9755430375717715], "time": [193.31020951271057, 170.85744953155518, 169.30305671691895, 171.3796513080597, 176.18376541137695]}, "test": {"avg_auc": 0.9731832322684708, "time": 1565.8144643306732}, "stats": [null, null, null, null, null], "valid": {"avg_auc": [0.9740353187980927, 0.9753683231542453, 0.9738059418782935, 0.9702530483365489, 0.9710214002453057], "time": [157.64909863471985, 158.58998560905457, 158.75370740890503, 158.06714916229248, 158.31521773338318]}, "train_full": {"avg_auc": 0.9753492512123872}}, "sampler": "challenges.toxicity.samplers.gru", "duration": 4187.989343, "summary": "e097a23e58f5f681ff4b19995207a31e", "life": [{"dt": "Mon Feb 26 09:53:14 2018", "state": "success"}], "end": "2018-02-26 09:53:12.733779", "traceback": "", "state": "success"}